{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33a5bf82-230b-40ab-a260-c9792b127604",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e23fba-ec22-4df5-9825-44065306ad92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from joblib import dump\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f6742-78ea-4aed-acbc-67b99ff28970",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9618149d-e744-4cc2-928e-f6f58e452bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_interim = pd.read_feather(Path('../data/interim/dataset_interim.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6677bf09-2115-4180-8a8b-abc72e8453f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_interim.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23795485-c17c-42aa-9dfb-b06143e0b2ce",
   "metadata": {},
   "source": [
    "## Selecting/Tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c96b183-8c10-46cb-bd6e-179893d99178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df_interim.drop(['fraudulent', 'index'], axis=1)\n",
    "y = df_interim.drop(['description', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b30cb-51b1-410b-aae7-3d811b17ba13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(\n",
    "    x, y, stratify=y, test_size=0.15,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9490b2-9d28-43ea-92ef-6fb6401fd1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Tune the model.\"\"\"\n",
    "    # Oversample because the dataset is unbalanced.\n",
    "    #oversample = trial.suggest_categorical('oversample', ['SMOTE', 'ADASYN'])\n",
    "    #if oversample == 'SMOTE':\n",
    "    #    k_neighbors = trial.suggest_int('oversample_n_neighbors', 2, 5, 1)\n",
    "    #    oversampler = SMOTE(\n",
    "    #        random_state=42, n_jobs=-1, k_neighbors=k_neighbors\n",
    "    #    )\n",
    "    #else:\n",
    "    #    n_neighbors = trial.suggest_int('oversample_n_neighbors', 2, 5, 1)\n",
    "    #    oversampler = ADASYN(\n",
    "    #        random_state=42, n_jobs=-1, n_neighbors=n_neighbors\n",
    "    #    )\n",
    "    k_neighbors = trial.suggest_int('oversample_n_neighbors', 2, 5, 1)\n",
    "    oversampler = SMOTE(random_state=42, n_jobs=-1, k_neighbors=k_neighbors)\n",
    "    \n",
    "    # curse of dimensionality\n",
    "    #features_selection = trial.suggest_categorical(\n",
    "    #    'features_selection', \n",
    "    #    ['random','pca']\n",
    "    #    )\n",
    "    #if features_selection == 'random':\n",
    "    #    select = SelectFromModel(RandomForestClassifier(\n",
    "    #        random_state=42, \n",
    "    #        n_jobs=-1\n",
    "    #        ))\n",
    "    #else:\n",
    "    #    n_components = trial.suggest_int('select_n_components', 40, 300, 5)\n",
    "    #    select = SparsePCA(\n",
    "    #        n_components=n_components, \n",
    "    #        random_state=42, \n",
    "    #        n_jobs=-1\n",
    "    #        )\n",
    "    select = SelectFromModel(\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    )\n",
    "\n",
    "    idf_params = {\n",
    "        'ngram_range': trial.suggest_categorical('vect_ngram_range',[1, 2]),\n",
    "        'max_df': trial.suggest_float('vect_max_df', 0.7, 1),\n",
    "        'min_df': trial.suggest_float('vect_min_df', 0.001, 0.1),\n",
    "        'norm': trial.suggest_categorical('vect_norm', ['l1', 'l2']),\n",
    "        'use_idf': trial.suggest_categorical('vect_use_idf',[True, False]),\n",
    "    }\n",
    "    # Re-weight (or not) features with inverse document-frequency.\n",
    "    pipe = Pipeline([\n",
    "        (\n",
    "            'vect', TfidfVectorizer(\n",
    "                decode_error='replace',\n",
    "                strip_accents='unicode',\n",
    "                ngram_range=(1, idf_params['ngram_range']),\n",
    "                max_df=idf_params['max_df'],\n",
    "                min_df=idf_params['min_df'],\n",
    "                norm=idf_params['norm'],\n",
    "                use_idf=idf_params['use_idf'],\n",
    "            )\n",
    "        ),\n",
    "        # False to work on sparse matrix.\n",
    "        (\n",
    "            'std', StandardScaler(with_mean=False)\n",
    "        ),\n",
    "    ])\n",
    "    # models\n",
    "    classifier = trial.suggest_categorical(\n",
    "        'clf',\n",
    "        ['LinearSVC', 'LogisticRegression', 'MultinomialNB']\n",
    "    )\n",
    "    match classifier:\n",
    "        case 'LinearSVC':\n",
    "            clf_params = {\n",
    "                'C': trial.suggest_float('clf_C', 1e-10, 1e5),\n",
    "                'class_weight': trial.suggest_categorical(\n",
    "                'clf_class_weight', ['balanced', None]\n",
    "                ),\n",
    "                'random_state': 42,\n",
    "                'max_iter': 10_000,\n",
    "                'fit_intercept': False,\n",
    "                'loss': trial.suggest_categorical(\n",
    "                    'clf_loss', ['hinge', 'squared_hinge']\n",
    "                ),\n",
    "            }\n",
    "            clf_obj = LinearSVC(**clf_params)\n",
    "        case 'LogisticRegression':\n",
    "            clf_params = {\n",
    "                'C': trial.suggest_float('clf_C', 1e-10, 1e5),\n",
    "                'class_weight': trial.suggest_categorical(\n",
    "                'clf_class_weight', ['balanced', None]\n",
    "                ),\n",
    "                'random_state': 42,\n",
    "                'max_iter': 10_000,\n",
    "                'fit_intercept': False,\n",
    "                'l1_ratio': trial.suggest_float(\n",
    "                    'clf_l1_ratio', 0.001, 0.999\n",
    "                ),\n",
    "            }\n",
    "            clf_obj = LogisticRegression(\n",
    "                solver='saga', n_jobs=-1, penalty='elasticnet', **clf_params\n",
    "            )\n",
    "        case 'MultinomialNB':\n",
    "            clf_params = {\n",
    "                'alpha': trial.suggest_float('clf_alpha', 1e-10, 1e5),\n",
    "                'fit_prior': trial.suggest_categorical(\n",
    "                    'clf_prior', [True, False]\n",
    "                )\n",
    "            }\n",
    "            clf_obj = MultinomialNB(**clf_params)\n",
    "    \n",
    "    # stratification\n",
    "    skf = StratifiedKFold(5)\n",
    "    \n",
    "    x_train = xtrain.reset_index(drop=True)\n",
    "    y_train = ytrain.reset_index(drop=True)\n",
    "\n",
    "    x_train['fold'] = -1\n",
    "    y_train['fold'] = -1\n",
    "\n",
    "    for fold, (train_id, valid_id) in enumerate(\n",
    "        skf.split(\n",
    "            x_train.iloc[:, :-1], \n",
    "            y_train.iloc[:, :-1]\n",
    "        )\n",
    "    ):\n",
    "        x_train.loc[valid_id, ['fold']] = fold\n",
    "        y_train.loc[valid_id, ['fold']] = fold\n",
    "\n",
    "    scores = []\n",
    "    for fold in np.unique(x_train.iloc[:, -1]):  \n",
    "        \n",
    "        x_train_fold = x_train.loc[\n",
    "            x_train['fold'] != fold, ['description']\n",
    "        ]\n",
    "        y_train_fold = y_train.loc[\n",
    "            y_train['fold'] != fold, ['fraudulent']\n",
    "            ].astype('int')\n",
    "\n",
    "        x_valid = x_train.loc[x_train['fold'] == fold, ['description']]\n",
    "        y_valid = y_train.loc[\n",
    "            y_train['fold'] == fold, ['fraudulent']\n",
    "            ].astype('int')\n",
    "            \n",
    "        x = pipe.fit_transform(x_train_fold.iloc[:, -1])\n",
    "        xvalid = pipe.transform(x_valid.iloc[:, -1])\n",
    "    \n",
    "        x, y = oversampler.fit_resample(x, y_train_fold.iloc[:, -1])\n",
    "    \n",
    "        x = select.fit_transform(x.toarray(), y) \n",
    "        xvalid = select.transform(xvalid.toarray())\n",
    "\n",
    "        clf_obj.fit(x, y)\n",
    "        y_pred = clf_obj.predict(xvalid)\n",
    "\n",
    "        score = balanced_accuracy_score(y_valid, y_pred, adjusted=True)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036d474-64ff-46a8-9d32-0773b3210e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=2),\n",
    "    storage='sqlite:///../results/train_opt.db', \n",
    "    study_name='control',\n",
    "    load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a9261-3de8-4fe0-9477-843702e6ba46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = optuna.load_study(\n",
    "    study_name='control', storage='sqlite:///../results/train_opt.db'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c30e9-ee2e-4c23-a1fb-18984595511d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100d2d3-78f4-48b5-9de4-d327bd5ceeb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d3ca0-927d-465f-a89a-78048afb93a5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4613ee3-d087-4cb2-b73e-4b425cf7ea03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(x_train, y_train, x_valid, **kwargs):\n",
    "    \"\"\"Train the best model.\"\"\"\n",
    "    pipe = Pipeline([\n",
    "        ('vect', TfidfVectorizer(\n",
    "            max_df=kwargs['vect_max_df'],\n",
    "            min_df=kwargs['vect_min_df'],\n",
    "            ngram_range=(1, kwargs['vect_ngram_range']),\n",
    "            norm=kwargs['vect_norm'],\n",
    "            use_idf=kwargs['vect_use_idf'])),\n",
    "        ('std', StandardScaler(with_mean=False)),\n",
    "    ])\n",
    "    \n",
    "    oversampler = SMOTE(\n",
    "        random_state=42, \n",
    "        n_jobs=-1, \n",
    "        k_neighbors=kwargs['oversample_n_neighbors']\n",
    "    )\n",
    "    \n",
    "    select = SelectFromModel(\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    )\n",
    "    \n",
    "    clf_obj = LogisticRegression(\n",
    "        solver='saga', \n",
    "        n_jobs=-1,\n",
    "        penalty='elasticnet',\n",
    "        C=kwargs['clf_C'],\n",
    "        class_weight=kwargs['clf_class_weight'],\n",
    "        l1_ratio=kwargs['clf_l1_ratio'],\n",
    "        random_state=42,\n",
    "        max_iter=10_000,\n",
    "        fit_intercept=False\n",
    "        )\n",
    "    \n",
    "    x = pipe.fit_transform(x_train.iloc[:, -1])\n",
    "    xvalid = pipe.transform(x_valid.iloc[:, -1])\n",
    "    \n",
    "    x, y = oversampler.fit_resample(x, y_train.iloc[:, -1])\n",
    "    \n",
    "    x = select.fit_transform(x.toarray(), y) \n",
    "    xvalid = select.transform(xvalid.toarray())\n",
    "\n",
    "    clf_obj.fit(x, y)\n",
    "    y_pred = clf_obj.predict(xvalid)\n",
    "    y_hat = clf_obj.decision_function(xvalid)\n",
    "    \n",
    "    return pipe, select, clf_obj, y_pred, y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd2c169-96db-44c0-a7bf-bc30712b3d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe, select, clf_obj, y_pred, y_hat = train(\n",
    "    xtrain, ytrain, xvalid, **results.best_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cfe9b2-b96e-41f7-a97b-ca3ed2dc381a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "balanced_accuracy_score(yvalid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65074c-b418-4d8e-a69d-9bb18b2c6bde",
   "metadata": {},
   "source": [
    "## Dumping the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f0d05-c03d-4f08-9e42-12d54ce0c071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dump(pipe, Path('../models/pipe.joblib'))\n",
    "dump(select, Path('../models/select.joblib'))\n",
    "dump(clf_obj, Path('../models/model.joblib'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
